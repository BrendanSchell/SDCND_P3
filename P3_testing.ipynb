{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8036"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Flatten, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-89489d35e89d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/IMG/center_2016_12_01_13_30_48_287.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplot_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#img = cv2.flip(preprocess(img),1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "def preprocess(img):\n",
    "    img = img[40:120,:]\n",
    "    img = cv2.resize(img,(64,64))\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2YCR_CB)\n",
    "    return img\n",
    "img=mpimg.imread('data/IMG/center_2016_12_01_13_30_48_287.jpg')\n",
    "img2=preprocess(img)\n",
    "plot_image = np.concatenate((img,img2))\n",
    "print(img.shape)\n",
    "#img = cv2.flip(preprocess(img),1)\n",
    "plt.imshow(plot_image)\n",
    "print(img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import random\n",
    "df = pd.read_csv('data/driving_log.csv')\n",
    "#rand_locs = np.random.choice(len(df['steering']),5)\n",
    "#df_filtered = df.loc[rand_locs,:]\n",
    "df_filtered = df\n",
    "X = []\n",
    "y = []\n",
    "path = 'data/'\n",
    "STEERING_OFFSET = 0.25\n",
    "mn = np.mean(df_filtered['steering'])\n",
    "std = np.std(df_filtered['steering'])\n",
    "for i in range(len(df_filtered)):\n",
    "        c = mpimg.imread(path + df_filtered.iloc[i,:]['center'])\n",
    "        l = mpimg.imread(path + df_filtered.iloc[i,:]['left'][1:])\n",
    "        r = mpimg.imread(path + df_filtered.iloc[i,:]['right'][1:])\n",
    "        num = np.random.normal(mn,std)\n",
    "        if not ((abs(df_filtered.iloc[i,:]['steering']) < 0.1) and df_filtered.iloc[i,:]['steering'] < num): \n",
    "            X.append(c)\n",
    "            X.append(cv2.flip(c,1))\n",
    "            y.append(df_filtered.iloc[i,:]['steering'])\n",
    "            y.append(-1.*df_filtered.iloc[i,:]['steering'])\n",
    "            X.append(l)\n",
    "            X.append(cv2.flip(l,1))\n",
    "            X.append(r)\n",
    "            X.append(cv2.flip(r,1))\n",
    "            y.append(df_filtered.iloc[i,:]['steering'] + STEERING_OFFSET)\n",
    "            y.append(-1.*(df_filtered.iloc[i,:]['steering'] + STEERING_OFFSET))\n",
    "            y.append(df_filtered.iloc[i,:]['steering'] - STEERING_OFFSET)\n",
    "            y.append(-1.*(df_filtered.iloc[i,:]['steering'] - STEERING_OFFSET))\n",
    "for i, el in enumerate(X):\n",
    "    X[i] = preprocess(el)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_3 (BatchNorma (None, 64, 64, 3)     12          batchnormalization_input_3[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_11 (Convolution2D) (None, 30, 30, 24)    1824        batchnormalization_3[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_17 (Activation)       (None, 30, 30, 24)    0           convolution2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 30, 30, 24)    0           activation_17[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_12 (Convolution2D) (None, 13, 13, 36)    21636       dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_18 (Activation)       (None, 13, 13, 36)    0           convolution2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 5, 5, 48)      43248       activation_18[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_19 (Activation)       (None, 5, 5, 48)      0           convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 3, 3, 64)      27712       activation_19[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_20 (Activation)       (None, 3, 3, 64)      0           convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 1, 1, 64)      36928       activation_20[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_21 (Activation)       (None, 1, 1, 64)      0           convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 64)            0           activation_21[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 64)            0           flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 100)           6500        dropout_6[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_22 (Activation)       (None, 100)           0           dense_9[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_10 (Dense)                 (None, 50)            5050        activation_22[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_23 (Activation)       (None, 50)            0           dense_10[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_11 (Dense)                 (None, 10)            510         activation_23[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "activation_24 (Activation)       (None, 10)            0           dense_11[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 1)             11          activation_24[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 143,431\n",
      "Trainable params: 143,425\n",
      "Non-trainable params: 6\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Flatten, Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=X[0].shape))\n",
    "model.add(Conv2D(24, 5, 5,subsample=(2,2), dim_ordering='tf'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(36, 5, 5,subsample=(2,2) ,dim_ordering='tf'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(48, 5, 5,subsample=(2,2), dim_ordering='tf'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(64, 3, 3, dim_ordering='tf'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Conv2D(64, 3, 3, dim_ordering='tf'))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'GraphViz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0846e74b3199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mGraphViz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'GraphViz'"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import GraphViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "26496/26496 [==============================] - 31s - loss: 0.0194 - acc: 0.1280 - val_loss: 0.0176 - val_acc: 0.1220\n",
      "Epoch 2/5\n",
      "26496/26496 [==============================] - 29s - loss: 0.0188 - acc: 0.1279 - val_loss: 0.0181 - val_acc: 0.1212\n",
      "Epoch 3/5\n",
      "26496/26496 [==============================] - 29s - loss: 0.0186 - acc: 0.1279 - val_loss: 0.0167 - val_acc: 0.1217\n",
      "Epoch 4/5\n",
      "26496/26496 [==============================] - 29s - loss: 0.0177 - acc: 0.1280 - val_loss: 0.0167 - val_acc: 0.1261\n",
      "Epoch 5/5\n",
      "26496/26496 [==============================] - 29s - loss: 0.0172 - acc: 0.1279 - val_loss: 0.0163 - val_acc: 0.1196\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "imageGen = ImageDataGenerator()\n",
    "history = model.fit_generator(imageGen.flow(X_train, y_train, batch_size=256), samples_per_epoch=len(X_train),\n",
    "                              nb_epoch=5, validation_data=imageGen.flow(X_val, y_val, batch_size=256),\n",
    "                              nb_val_samples=len(X_val))\n",
    "\n",
    "model.save_weights(\"model.h5\", True)\n",
    "with open('model.json', 'w') as outfile:\n",
    "    json.dump(model.to_json(), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata .......\n",
      "Solving package specifications: ..........\n",
      "\n",
      "Package plan for installation in environment /home/carnd/anaconda3/envs/carnd-term1:\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    libtool-2.4.2              |                0         547 KB\n",
      "    pillow-4.0.0               |           py35_0         863 KB\n",
      "    pango-1.39.0               |                0         777 KB\n",
      "    graphviz-2.38.0            |                4        12.0 MB\n",
      "    qt-4.8.7                   |                4        32.7 MB\n",
      "    matplotlib-1.5.1           |      np111py35_0         8.4 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        55.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "    expat:      2.1.0-0                      \n",
      "    graphviz:   2.38.0-4                     \n",
      "    libtool:    2.4.2-0                      \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    fontconfig: 2.11.1-5          conda-forge --> 2.11.1-6         \n",
      "    pillow:     3.4.2-py35_0      conda-forge --> 4.0.0-py35_0     \n",
      "    qt:         4.8.7-3           conda-forge --> 4.8.7-4          \n",
      "\n",
      "The following packages will be SUPERCEDED by a higher-priority channel:\n",
      "\n",
      "    cairo:      1.14.6-0          conda-forge --> 1.12.18-6        \n",
      "    freetype:   2.6.3-1           conda-forge --> 2.5.5-1          \n",
      "    harfbuzz:   1.3.4-0           conda-forge --> 0.9.39-1         \n",
      "    matplotlib: 1.5.3-np111py35_3 conda-forge --> 1.5.1-np111py35_0\n",
      "    pango:      1.40.3-0          conda-forge --> 1.39.0-0         \n",
      "    pixman:     0.34.0-0          conda-forge --> 0.32.6-0         \n",
      "\n",
      "Fetching packages ...\n",
      "libtool-2.4.2- 100% |################################| Time: 0:00:00   4.73 MB/s\n",
      "pillow-4.0.0-p 100% |################################| Time: 0:00:00   8.43 MB/s\n",
      "pango-1.39.0-0 100% |################################| Time: 0:00:00   8.85 MB/s\n",
      "graphviz-2.38. 100% |################################| Time: 0:00:00  26.33 MB/s\n",
      "qt-4.8.7-4.tar 100% |################################| Time: 0:00:00  37.40 MB/s\n",
      "matplotlib-1.5 100% |################################| Time: 0:00:00  14.31 MB/s\n",
      "Extracting packages ...\n",
      "[      COMPLETE      ]|###################################################| 100%\n",
      "Unlinking packages ...\n",
      "[      COMPLETE      ]|###################################################| 100%\n",
      "Linking packages ...\n",
      "CondaOSError: OS error: failed to link (src='/home/carnd/anaconda3/pkgs/qt-4.8.7-4/mkspecs/default', dst='/home/carnd/anaconda3/envs/carnd-term1/mkspecs/default', type=3, error=FileExistsError(17, 'File exists'))\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install GraphViz -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata .......\n",
      "Solving package specifications: ....\n",
      "UnsatisfiableError: The following specifications were found to be in conflict:\n",
      "  - pydot\n",
      "  - python 3.5*\n",
      "Use \"conda info <package>\" to see the dependencies for each package.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
